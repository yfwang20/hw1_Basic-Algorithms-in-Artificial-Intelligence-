# 人工智能基础算法 第一次作业 实验报告

王怡丰 2024310877

## 代码整体描述

代码基于Python实现，主要包括以下几个部分：

- `calculate_Euclidean_distance`等4个函数，用于具体计算不同图片之间的不同距离
- `calculate_and_compare`等4个函数，用于在上述函数的基础上计算与测试集中图片最近的训练集图片的序号
- `downsampling_2_max`等3个函数，用于对图片进行降采样、分辨率差值
- 主函数，主要包含5个部分，分别对应5个任务

每个任务的大致逻辑是首先计算测试集中的每个图片相对于训练集中的每个图片的距离，并找出其中与每个测试集图片距离最小的训练集图片的标号，然后比较找到的图片对应的标签与测试集图片标签，计算符合数量。代码实现了第一个计算过程的全部矩阵化计算，但由于电脑的内存限制，对于测试集仍使用for循环，并设置了多线程计算，对于不同任务，根据单个测试集图片的计算规模，在比较计算速度后分别选择了2/4线程计算。

## 实验结果

### 任务1

实现了基于欧几里得距离的最近邻分类器，以A为训练集，B为测试集进行了测试，测试结果如下

| 符合个数 | 分类准确率 | 计算时间/s |
| :------: | :--------: | :--------: |
|  28916   |  96.387%   |   423.6    |

### 任务2

实现了基于曼哈顿距离、$L_{\infty}$范数距离以及$p=4$的闵可夫斯基距离，以A为训练集，B为测试集进行了测试，测试结果如下

|            | 欧几里得距离 | 曼哈顿距离 | $L_{\infty}$范数距离 | $p=4$的闵可夫斯基距离 |
| :--------: | :----------: | :--------: | :------------------: | :-------------------: |
|  符合个数  |    28916     |   28708    |        23615         |         29024         |
| 分类准确率 |   96.387%    |  95.693%   |       78.717%        |        96.746%        |
| 计算时间/s |    423.6     |   311.5    |        307.2         |        1426.5         |

欧几里得、曼哈顿距离可分别看作$p=2、1$情况下的闵可夫斯基距离，这三者之间，随着$p$的增大，计算量增加，计算时间明显增加；另一方面，随着$p$的增大，距离会放大图像之间差距较大的像素的影响，而不同的数字间有更多此类像素，因而准确率提高；而对于曼哈顿距离，由于其只需计算差距最大的像素，因而计算时间很短，但这一特征在数字识别中不够具有区分性，即使是相同的数字，在经过旋转后也可能在某些像素上有很大的差距，因而准确率明显偏低。

### 任务3

实现了$K=3,5,7,11,31$的$K$近邻分类器，以A为训练集，B为测试集进行了测试，各方法均采用欧几里得距离，测试结果如下

|     K      |    1    |    3    |    5    |    7    |   11    |   31    |
| :--------: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: |
|  符合个数  |  28916  |  28932  |  28911  |  28870  |  28776  |  28376  |
| 分类准确率 | 96.387% | 96.440% | 96.370% | 96.233% | 95.920% | 94.587% |
| 计算时间/s |  423.6  |  442.3  |  460.4  |  460.5  |  456.1  |  459.5  |

相比于$K=1$，当$K$增大时，计算时间增大，这是由于相比于$K=1$时直接搜索最大值，本算法中$K>1$需要对距离矩阵进行排序，这增大了计算量，但$K$较大时计算量差别不大；而随着$K$增大，准确率先增大后减小，在$K>7$时出现比较明显的下滑，这可能是由于若$K$过小，判断可能会受到某些单个图片的影响，造成误判，随着$K$增大，更多图片的引入能够减小单个图片对于判断的影响，使判断更加稳定，但若$K$过大，可能会引入过多无关的、不太接近的图片，引起误判。

### 任务4

在数据集C上， 实现留一法交叉检验并报告结果，采用欧几里得距离，测试结果如下

|            | A为训练集，B为测试集 | 在数据集C上实现留一法 |
| :--------: | :------------------: | :-------------------: |
|  符合个数  |        28916         |         58423         |
| 分类准确率 |       96.387%        |        97.372%        |
| 计算时间/s |        423.6         |        3379.5         |

留一法在计算量上可以看作测试的训练集、测试集大小均为60000，其计算规模相比于原始情况变为4倍，且由于此项目的计算是在个人电脑上进行的，受限于内存，计算规模增大会进一步提高计算时间，因而此例中在C上进行的留一法的计算时间大幅高于A为训练集、B为测试集的计算时间；另一方面，在数据集上实现留一法相当于将训练集的样本数量增大一倍，这提高了分类准确率。

### 任务5

对数据集A和B同时做如下3种变换：2倍降采样，4倍降采样，和2倍分辨率差值，其中降采样取区域内最大值，分辨率差值采用双线性插值法，以A为训练集，B为测试集进行了测试，采用欧几里得距离，测试结果如下

|            | 无变化  | 2倍降采样 | 4倍降采样 | 2倍分辨率差值 |
| :--------: | :-----: | :-------: | :-------: | :-----------: |
|  符合个数  |  28916  |   28844   |   25592   |     29034     |
| 分类准确率 | 96.387% |  96.147%  |  85.307%  |    96.780%    |
| 计算时间/s |  423.6  |   105.3   |   29.6    |    14363.5    |

2倍降采样、4倍降采样分别将计算规模缩小了4、16倍，计算时间因而有大幅度缩短，而2倍分辨率差值则将计算规模增大4倍，且由于笔记本内存限制，计算时间会有非常大幅度的增加，与项目中其他例子不同，2倍分辨率差值采用另一更强的电脑计算，若使用与其他例子相同的电脑，则预估需要超过22500秒。而对于准确率，降采样损失了图片的许多特征，虽然取最大值的方法能够尽可能保存重要的特征，使2倍降采样时准确率不下降太多，但4倍时仍有非常明显的下降；而2倍分辨率差值则能够进一步放大图片特征，提高判断准确性